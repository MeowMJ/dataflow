# Dataflow Instruction System Documentation

## Overview

This document describes a dataflow instruction system based on PE (Processing Element) arrays. The system employs spatial mapping to distribute computational tasks across different PEs, achieving parallel computation through directional data transmission.

## Instruction Types Summary

### 1. Arithmetic Instructions

#### ADD
- **Function**: Integer addition operation
- **Operands**: Two input operands
- **Example**: `ADD, [North, R], [NorthEast, R] -> [East, R]`

#### FADD  
- **Function**: Floating-point addition operation
- **Operands**: Two floating-point input operands
- **Example**: `FADD, [West, R], [NorthWest, R] -> [SouthWest, R]`

### 2. Comparison Instructions

#### ICMP
- **Function**: Integer comparison operation
- **Operands**: Two integer input operands
- **Example**: `ICMP, [West, R], [NorthWest, R] -> [West, R]`

### 3. Logical Instructions

#### NOT
- **Function**: Logical NOT operation
- **Operands**: One input operand
- **Example**: `NOT, [Local, R] -> [NorthEast, R]`

### 4. Constant Instructions

#### CONSTANT
- **Function**: Generate constant values
- **Operands**: Immediate values
- **Examples**: 
  - `CONSTANT, IMM[10] -> [Local, R]`
  - `CONSTANT, IMM[0] -> [Local, R]`
  - `CONSTANT, IMM[1] -> [Local, R]`
  - `CONSTANT, IMM[3.000000e+00] -> [Local, R]`
  - `CONSTANT, IMM[0.000000e+00] -> [South, R]`

### 5. Control Flow Instructions

#### PHI
- **Function**: Dataflow merge node for value selection in loops
- **Operands**: Multiple input operands
- **Examples**: 
  - `PHI, [Local, R], [North, R] -> [South, R]`
  - `PHI, [Local, R], [Local, R] -> [East, R]`

### 6. Data Transfer Instructions

#### GRANT_ALWAYS
- **Function**: Unconditional data transfer
- **Operands**: One input operand
- **Example**: `GRANT_ALWAYS, [Local, R] -> [SouthEast, R]`

#### GRANT_ONCE
- **Function**: One-time data transfer
- **Operands**: One input operand
- **Example**: `GRANT_ONCE, [Local, R] -> [South, R]`

#### GRANT_PREDICATE
- **Function**: Conditional data transfer
- **Operands**: Two input operands (condition + data)
- **Example**: `GRANT_PREDICATE, [Local, R], [East, R] -> [Local, R]`

### 7. Program Control Instructions

#### RETURN
- **Function**: Function return
- **Operands**: Return value
- **Example**: `RETURN, [Local, R]`

#### NOP
- **Function**: No operation
- **Operands**: None
- **Example**: `NOP`

## Direction System

### Supported Directions
- **Local**: Local operation, data does not move between PEs
- **North**: Transfer northward
- **South**: Transfer southward  
- **East**: Transfer eastward
- **West**: Transfer westward
- **NorthEast**: Transfer northeast
- **NorthWest**: Transfer northwest
- **SouthEast**: Transfer southeast
- **SouthWest**: Transfer southwest

### Local Direction Usage Analysis

#### How Local Direction is Generated:
Local direction is automatically generated by the code generation pass when:

1. **No Source Found**: When an operation has no input operands or cannot find the defining operation's tile mapping
2. **No Destination Found**: When an operation's result has no users or cannot find the user's tile mapping  
3. **Same Tile**: When source and destination tiles have the same coordinates (dx=0, dy=0)

#### Code Generation Logic:
```cpp
// In calculateSourceDirection()
if (!found_src) {
  inst_obj["src_direction"] = "Local";
  inst_obj["src_tile"] = "(" + std::to_string(x) + "," + std::to_string(y) + ")";
}

// In calculateDestinationDirection()  
if (!found_dst) {
  inst_obj["dst_direction"] = "Local";
  inst_obj["dst_tile"] = "(" + std::to_string(x) + "," + std::to_string(y) + ")";
}

// Direction calculation when coordinates are the same
if (dx == 0 && dy == 0) return "Local";
```

#### Cases where Local direction appears:

1. **CONSTANT Instructions**: Always have Local as src_direction (no input operands)
   - Example: `CONSTANT, IMM[10] -> [Local, R]`
   - Reason: No defining operation found for input

2. **Isolated Operations**: Operations whose results are not used by other PEs
   - Example: Operations with no users in the dataflow graph
   - Reason: No destination tile found

3. **Self-Referential Operations**: Operations that produce results used within the same PE
   - Example: `PHI, [Local, R], [Local, R] -> [East, R]`
   - Reason: Source and destination tiles are the same

4. **Data Flow Boundaries**: Operations at function entry/exit points
   - Example: RETURN operations
   - Reason: No subsequent operations to determine destination

#### What Local Actually Means:

**Local does NOT mean local registers.** Instead, it indicates:

1. **No Inter-PE Communication**: Data does not need to move between PEs
2. **Buffer-Based Access**: Data is accessed directly from direction buffers within the same PE
3. **Data Flow Continuity**: The operation continues the data flow within the local PE's buffer system
4. **Fallback Mechanism**: When the code generator cannot determine a specific direction, it defaults to Local

#### Why Local is Used:

1. **Data Flow Completeness**: Ensures every operation has defined input/output directions
2. **Buffer System Integration**: Maintains consistency with the direction-based buffer architecture
3. **Code Generation Robustness**: Provides fallback when tile mappings are incomplete
4. **Performance Optimization**: Avoids unnecessary data movement when operations are co-located

## PE Array Structure

### Example PE Layout
```
PE(1,0)  PE(1,1)  PE(1,2)
PE(2,0)  PE(2,1)  PE(2,2)  
PE(3,0)  PE(3,1)  PE(3,2)
```

### Execution Modes
- **Loop**: Loop execution mode for computations requiring multiple iterations
- **Once**: Single execution mode for one-time computations

## Dataflow Characteristics

1. **Spatial Parallelism**: Multiple PEs execute different computational tasks simultaneously
2. **Pipelining**: Pipeline execution through time-step scheduling
3. **Data-Driven**: Instruction scheduling based on data dependencies
4. **Directional Communication**: PE-to-PE data exchange through 8 directions

## Buffer-Based Architecture

### Key Design Principle
- **Direction-Based Buffers**: Data is stored in direction-specific input/output buffers
- **No Traditional Registers**: PEs do not have conventional local registers
- **Buffer Continuity**: Local direction indicates data stays within the same PE's buffer system
- **Efficient Communication**: Minimizes data movement by using buffer data directly

### Buffer Types
- **Input Buffers**: Store incoming data from different directions (North, South, East, West, etc.)
- **Output Buffers**: Store data to be sent to different directions
- **Local Buffer Access**: When direction is Local, data is accessed from buffers within the same PE

### Local Direction in Buffer Context
When an operation uses Local direction:
- **Input**: Data is read from the local PE's input buffers (no inter-PE transfer needed)
- **Output**: Data is written to the local PE's output buffers (no inter-PE transfer needed)
- **Continuity**: The data flow continues within the same PE's buffer system
- **Fallback**: Used when the code generator cannot determine a specific direction

## Application Scenarios

- Digital Signal Processing
- Matrix Operations
- Image Processing
- Scientific Computing
- Machine Learning Inference

## Mapping to Traditional Hardware Instructions

### Overview
The dataflow instructions described above are specific to dataflow architectures. When targeting traditional hardware (CPUs, GPUs, or conventional accelerators), these instructions need to be mapped to standard assembly instructions.

### Instruction Mapping Strategies

#### 1. GRANT Instructions Mapping

**GRANT_ALWAYS**
```assembly
# Dataflow: GRANT_ALWAYS, [Local, R] -> [South, R]
# Traditional: Direct register move
mov r1, r2          # Move data from source to destination register
```

**GRANT_ONCE**
```assembly
# Dataflow: GRANT_ONCE, [Local, R] -> [South, R]
# Traditional: Conditional move with flag
cmp flag, 0         # Check if already used
je skip_move        # Skip if already used
mov r1, r2          # Move data
mov flag, 1         # Mark as used
skip_move:
```

**GRANT_PREDICATE**
```assembly
# Dataflow: GRANT_PREDICATE, [Local, R], [East, R] -> [Local, R]
# Traditional: Conditional move
cmp predicate, 1    # Check predicate condition
cmove result, value # Conditional move if predicate is true
```

#### 2. PHI Instruction Mapping

**PHI Operation**
```assembly
# Dataflow: PHI, [Local, R], [North, R] -> [South, R]
# Traditional: Multiple conditional moves or select operation

# Method 1: Using conditional moves
cmp condition, 1
cmove result, value1    # Move value1 if condition is true
cmovne result, value2   # Move value2 if condition is false

# Method 2: Using select operation (if available)
result = select(condition, value1, value2)

# Method 3: Using branch-based approach
cmp condition, 1
je use_value1
mov result, value2
jmp continue
use_value1:
mov result, value1
continue:
```

#### 3. Direction-Based Communication Mapping

**Inter-PE Communication**
```assembly
# Dataflow: ADD, [North, R], [NorthEast, R] -> [East, R]
# Traditional: Load from memory + computation + store

# Load operands from memory (simulating direction buffers)
load r1, [north_buffer_addr]      # Load from "North" buffer
load r2, [northeast_buffer_addr]  # Load from "NorthEast" buffer

# Perform computation
add r3, r1, r2

# Store result to "East" buffer
store [east_buffer_addr], r3
```

#### 4. CONSTANT Instruction Mapping

**Constant Generation**
```assembly
# Dataflow: CONSTANT, IMM[10] -> [Local, R]
# Traditional: Immediate load
mov r1, 10          # Load immediate value
```

### Implementation Approaches

#### 1. **Software Emulation**
- Implement dataflow semantics in software
- Use traditional instructions to simulate dataflow behavior
- Higher overhead but portable across different architectures

#### 2. **Hardware Abstraction Layer**
- Create a translation layer between dataflow and traditional instructions
- Map dataflow concepts to available hardware primitives
- Optimize for specific target architecture

#### 3. **Custom Hardware Design**
- Design specialized hardware units for dataflow operations
- Implement direction-based routing networks
- Create predicate-aware execution units

#### 4. **Hybrid Approach**
- Combine software emulation with hardware acceleration
- Use specialized instructions where available
- Fall back to software implementation for unsupported operations

### Memory Layout for Direction Buffers

```c
// Traditional memory layout for direction buffers
struct DirectionBuffers {
    uint64_t north_buffer[MAX_SIZE];
    uint64_t south_buffer[MAX_SIZE];
    uint64_t east_buffer[MAX_SIZE];
    uint64_t west_buffer[MAX_SIZE];
    uint64_t northeast_buffer[MAX_SIZE];
    uint64_t northwest_buffer[MAX_SIZE];
    uint64_t southeast_buffer[MAX_SIZE];
    uint64_t southwest_buffer[MAX_SIZE];
    uint64_t local_buffer[MAX_SIZE];
};
```

### Control Flow Implementation

#### Loop Execution
```assembly
# Dataflow Loop execution
# Traditional: Standard loop with condition checking

loop_start:
    # Execute loop body instructions
    cmp loop_condition, 0
    jne loop_start
```

#### Conditional Execution
```assembly
# Dataflow conditional execution using predicates
# Traditional: Branch-based or predicated execution

# Branch-based approach
cmp predicate, 1
je execute_block
jmp skip_block
execute_block:
    # Execute conditional code
skip_block:
```

### Performance Considerations

#### 1. **Memory Access Patterns**
- Direction buffers may cause irregular memory access
- Consider cache-friendly memory layouts
- Use prefetching for predictable access patterns

#### 2. **Branch Prediction**
- PHI operations can create complex control flow
- Use conditional moves when possible to avoid branches
- Profile and optimize hot paths

#### 3. **Parallelization**
- Dataflow naturally supports parallelism
- Map to SIMD instructions where applicable
- Use multiple execution units for independent operations

#### 4. **Synchronization**
- Dataflow operations may require synchronization
- Use atomic operations for shared resources
- Implement proper memory ordering

### Compiler Integration

#### 1. **IR Lowering**
- Lower dataflow IR to target-specific IR
- Map dataflow operations to available instructions
- Optimize for target architecture characteristics

#### 2. **Code Generation**
- Generate efficient assembly for target platform
- Use target-specific optimizations
- Handle platform-specific constraints

#### 3. **Runtime Support**
- Implement runtime library for dataflow operations
- Provide fallback implementations
- Support dynamic optimization

### Example: Complete Mapping

```c
// Dataflow program
PE(1,0): {
    Entry [East, R], [North, R] => Loop {
        ADD, [North, R], [NorthEast, R] -> [East, R]
        GRANT_PREDICATE, [Local, R], [East, R] -> [Local, R]
    }
}

// Traditional C implementation
void pe_1_0_loop() {
    while (loop_condition) {
        // Load operands from direction buffers
        uint64_t north_val = north_buffer[read_index];
        uint64_t northeast_val = northeast_buffer[read_index];
        
        // Perform addition
        uint64_t result = north_val + northeast_val;
        
        // Store to east buffer
        east_buffer[write_index] = result;
        
        // Conditional operation (GRANT_PREDICATE)
        if (local_condition) {
            local_buffer[write_index] = east_buffer[read_index];
        }
        
        // Update indices
        read_index = (read_index + 1) % BUFFER_SIZE;
        write_index = (write_index + 1) % BUFFER_SIZE;
    }
}
```

This mapping approach allows dataflow programs to run on traditional hardware while maintaining the conceptual benefits of dataflow execution. 